{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.5.0-py2.py3-none-any.whl (254 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting service-identity>=16.0.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h2<4.0,>=3.0\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting lxml>=3.5.0\n",
      "  Downloading lxml-4.6.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Collecting cryptography>=2.0\n",
      "  Downloading cryptography-3.4.8-cp36-abi3-win_amd64.whl (1.6 MB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pyOpenSSL>=16.2.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting zope.interface>=4.1.3\n",
      "  Downloading zope.interface-5.4.0-cp39-cp39-win_amd64.whl (210 kB)\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.5.zip (47 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting Twisted[http2]>=17.9.0\n",
      "  Downloading Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.1.16.tar.gz (3.2 MB)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\python39\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.3)\n",
      "Requirement already satisfied: pycparser in d:\\python39\\lib\\site-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.20)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in d:\\python39\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules in d:\\python39\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\python39\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: pyasn1 in d:\\python39\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting twisted-iocpsupport~=1.0.0\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp39-cp39-win_amd64.whl (45 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in d:\\python39\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (3.7.4.3)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting priority<2.0,>=1.1.0\n",
      "  Downloading priority-1.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: idna>=2.5 in d:\\python39\\lib\\site-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n",
      "Requirement already satisfied: setuptools in d:\\python39\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (49.2.1)\n",
      "Building wheels for collected packages: protego, PyDispatcher\n",
      "  Building wheel for protego (setup.py): started\n",
      "  Building wheel for protego (setup.py): finished with status 'done'\n",
      "  Created wheel for protego: filename=Protego-0.1.16-py3-none-any.whl size=7770 sha256=c83ab8958b31488aa05e82280864f711856fd3b0bf973d99abc1b24e25ac1a75\n",
      "  Stored in directory: c:\\users\\julie\\appdata\\local\\pip\\cache\\wheels\\9b\\e7\\dd\\5c83b657359b8cc1e116bfab153f22ee891862f6d78d1ddb82\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=12552 sha256=589e63c60ceaf174358b109d94cfff1362de8e823ca58e087a4986d706b67436\n",
      "  Stored in directory: c:\\users\\julie\\appdata\\local\\pip\\cache\\wheels\\a5\\de\\8a\\4b52190a95d99c042ec6bd5ad2de3a3c1b5ce71d69f0bbd036\n",
      "Successfully built protego PyDispatcher\n",
      "Installing collected packages: zope.interface, w3lib, twisted-iocpsupport, lxml, incremental, hyperlink, hyperframe, hpack, cssselect, constantly, Automat, Twisted, priority, parsel, jmespath, itemadapter, h2, cryptography, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.7.0 constantly-15.1.0 cryptography-3.4.8 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.4.0 itemloaders-1.0.4 jmespath-0.10.0 lxml-4.6.3 parsel-1.6.0 priority-1.3.0 protego-0.1.16 pyOpenSSL-20.0.1 queuelib-1.6.2 scrapy-2.5.0 service-identity-21.1.0 twisted-iocpsupport-1.0.2 w3lib-1.22.0 zope.interface-5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.loader import ItemLoader\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# ----------- CMD pour lancer -----------------\n",
    "# scrapy crawl kayak -o vol_Par_Mar_21_09.csv\n",
    "# scrapy crawl kayak -o vol_Par_Mar_21_09.json\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "class Vols(scrapy.Item):\n",
    "    # Creation des items pour les stockés dans le json\n",
    "    ranking = scrapy.Field()\n",
    "    compagnies = scrapy.Field()\n",
    "    heure_depart = scrapy.Field()\n",
    "    heure_arrivee = scrapy.Field()\n",
    "    airoport_depart = scrapy.Field()\n",
    "    airoport_arrivee = scrapy.Field()\n",
    "    vol = scrapy.Field()\n",
    "    heure_vol = scrapy.Field()\n",
    "    price = scrapy.Field()\n",
    "    time = scrapy.Field()\n",
    "    last_updated = scrapy.Field(serializer=str)\n",
    "\n",
    "\n",
    "class Kayak(scrapy.Spider):\n",
    "    # nom de mon scrapeur\n",
    "    name = \"kayak\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        # url = \"https://w ww.kayak.fr/\"\n",
    "        # aller simple\n",
    "        # https://www.kayak.fr/flights/PAR-MRS/2021-10-09?sort=bestflight_a\n",
    "        # Definie les variables\n",
    "        origin = \"PAR\"\n",
    "        destination = \"MRS\"\n",
    "        startdate = \"2021-09-21\"\n",
    "        # enddate = \"2021-09-09\"\n",
    "        # Construction de l'url\n",
    "        url = \"https://www.kayak.fr/flights/\" + origin + \"-\" + \\\n",
    "            destination + \"/\" + startdate + \"?sort=price_a\"\n",
    "        # &fs=stops=0\"\n",
    "        # ajouter une liste pour les dates\n",
    "        # ajouter une liste pour les destinations\n",
    "\n",
    "        print(' ------------------')\n",
    "        print(url)\n",
    "        print(' ------------------')\n",
    "\n",
    "        # reaquete url\n",
    "        request = scrapy.Request(\n",
    "            url=url,\n",
    "            callback=self.parse,\n",
    "        )\n",
    "        yield request\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        # Selectionne les balises\n",
    "        produits = response.css(\n",
    "            'div.Base-Results-ResultsList.Flights-Results-FlightResultsList')\n",
    "\n",
    "        # on initialise ranking\n",
    "        ranking = 0\n",
    "\n",
    "        for produit in produits.css('div.Base-Results-HorizonResult.Flights-Results-FlightResultItem'):\n",
    "            print(\"\")\n",
    "            # compagnies\n",
    "            compagnies = produit.css(\n",
    "                'div.leg-carrier img::attr(alt)').get().strip()\n",
    "            compagnies = compagnies.replace(\"Logo de \", \"\")\n",
    "            compagnies = str(compagnies).strip()\n",
    "            # airport depart et arrivee\n",
    "            all_airport = produit.css('div.bottom span::text').getall()\n",
    "            airports = []\n",
    "            for airport in all_airport:\n",
    "                airports.append(airport)\n",
    "            # airport depart\n",
    "            airoport_depart = airports[0]\n",
    "            airoport_depart = str(airoport_depart).replace(\"\\n\", \" \").strip()\n",
    "            # airport arrivee\n",
    "            airoport_arrivee = airports[2]\n",
    "            airoport_arrivee = str(airoport_arrivee).replace(\"\\n\", \" \").strip()\n",
    "            # heure_depart\n",
    "            heure_depart = produit.css('span.time-pair span::text').get()\n",
    "            # heure_arrivee\n",
    "            heure_arrivee = produit.css(\n",
    "                'span.arrival-time.base-time::text').get()\n",
    "            # vol\n",
    "            vol = produit.css('span.stops-text::text').get()\n",
    "            vol = str(vol).strip()\n",
    "            # heure_vol\n",
    "            heure_vol = produit.css('div.section.duration div::text').get()\n",
    "            heure_vol = str(heure_vol).strip()\n",
    "            # price\n",
    "            price = produit.css('span.unit-price span::text').get()\n",
    "            price = str(price).strip()\n",
    "            price = str(price).replace(\"\\xa0\", \" \")\n",
    "            price = price.replace(\"\\u20ac\", \"€\").replace(\"€\", \"€\")\n",
    "            # heure actuelle\n",
    "            my_time = datetime.now().isoformat()\n",
    "            loader = ItemLoader(item=Vols())\n",
    "            # ranking\n",
    "            ranking = ranking + 1\n",
    "            print(ranking)\n",
    "\n",
    "            loader.add_value(\"ranking\", ranking)\n",
    "            loader.add_value(\"compagnies\", compagnies)\n",
    "            loader.add_value(\"heure_depart\", heure_depart)\n",
    "            loader.add_value(\"heure_arrivee\", heure_arrivee)\n",
    "            loader.add_value(\"airoport_depart\", airoport_depart)\n",
    "            loader.add_value(\"airoport_arrivee\", airoport_arrivee)\n",
    "            loader.add_value(\"vol\", vol)\n",
    "            loader.add_value(\"heure_vol\", heure_vol)\n",
    "            loader.add_value(\"price\", price)\n",
    "            loader.add_value(\"time\", my_time)\n",
    "            yield loader.load_item()\n",
    "\n",
    "    # next_page = None\n",
    "    # next_page = response.css(\"*********************\").extract_first()\n",
    "    # if next_page is not None:\n",
    "    #     next_page = response.urljoin(next_page)\n",
    "    #     request = scrapy.Request(next_page, callback=self.parse)\n",
    "    #     # request.meta['ranking_start'] = ranking  #### Ranking à activer si la balise n'existe pas dans le code ########\n",
    "    #     yield request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
